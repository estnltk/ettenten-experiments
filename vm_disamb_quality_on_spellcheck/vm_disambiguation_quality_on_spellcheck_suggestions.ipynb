{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Vabamorf's disambiguation on spellchecker's suggestions\n",
    "\n",
    "In this tiny experiment, we use Vabamorf's spellchecker to add _**multiple normalized forms** to the **words layer**_, and examine, how this increased ambiguity affects the quality of Vabamorf's disambiguation in EstNLTK.\n",
    "\n",
    "We use EstNLTK's version 1.6.4beta (from the commit [52c921eb3d](https://github.com/estnltk/estnltk/tree/52c921eb3d06ebc0976c0dac84bc9b9f72b0491e)), and evaluate tools on the Estonian Web Treebank (EWTB) corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Estonian Web Treebank corpus\n",
    "\n",
    "You can download the UD format EWTB corpus from here: https://github.com/UniversalDependencies/UD_Estonian-EWT/ (exact commit: [6cd4d14](https://github.com/UniversalDependencies/UD_Estonian-EWT/tree/6cd4d1480c1f3dc89bcdddab56f04dc51bfa8b48))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = 'UD_Estonian-EWT-master'\n",
    "\n",
    "import os, os.path\n",
    "from ewtb_ud_utils import load_EWTB_ud_file_with_corrections\n",
    "\n",
    "# Load corpus files with corrections\n",
    "ud_layer_name = 'ud_syntax'\n",
    "loaded_texts  = []\n",
    "for fname in os.listdir( eval_data_dir ):\n",
    "    if fname.endswith('.conllu'):\n",
    "        fpath = os.path.join( eval_data_dir, fname )\n",
    "        text = load_EWTB_ud_file_with_corrections( fpath, ud_layer_name )\n",
    "        text.meta['file'] = fname\n",
    "        loaded_texts.append( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vabamorf's analysis and disambiguation (baseline: no spelling suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. No spelling suggestions + Vabamorf's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_0' == VabamorfAnalyzer + PostMorphAnalysisTagger\n",
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_0')\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_0')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_0', ud_layer_name, 'morph_0_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No spelling suggestions + Vabamorf's analysis with disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_1' == VabamorfTagger\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "\n",
    "vm_tagger = VabamorfTagger(output_layer='morph_1',\n",
    "                           input_words_layer='words')\n",
    "for text in loaded_texts:\n",
    "    vm_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_1', ud_layer_name, 'morph_1_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Vabamorf's analysis and disambiguation (baseline: no spelling suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: define the evaluation function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_disambiguation_of_all_words( texts, morph_0_diff_layer_name, \n",
    "                                             morph_1_diff_layer_name,\n",
    "                                             morph_2_diff_layer_name ):\n",
    "    '''Evaluates the disambiguation quality (correctly vs incorrectly disambiguated) on all words of the corpus.\n",
    "    '''\n",
    "    words_total = 0                  # total words (including words that cannot be aligned to UD morph)\n",
    "    correct_words_all = 0            # correct words (disambiguated + undisambiguated)\n",
    "    words_to_disambiguate = 0        # words needing disambiguation\n",
    "    words_disambiguated = 0          # words actually disambiguated\n",
    "    correctly_disambiguated = 0      # correct words (only disambiguated)\n",
    "    correct_analyses_total_after_disamb = 0\n",
    "    correct_analyses_total_before_disamb = 0\n",
    "    for text in texts:\n",
    "        morph_0_diff = text[morph_0_diff_layer_name]\n",
    "        morph_1_diff = text[morph_1_diff_layer_name]\n",
    "        morph_2_diff = text[morph_2_diff_layer_name]\n",
    "        assert len( morph_0_diff ) == len( morph_1_diff )\n",
    "        assert len( morph_1_diff ) == len( morph_2_diff )\n",
    "        for word_1, word_2, word_3 in zip(morph_0_diff, morph_1_diff, morph_2_diff):\n",
    "            if word_1.annotations[0]['full_match'] or word_2.annotations[0]['full_match']:\n",
    "                # Look only words that obtained a full match:\n",
    "                # 1) with the default morphological analysis, or\n",
    "                # 2) with the extended morphological analysis based on normalized word forms\n",
    "                correct_analyses_total_before_disamb += 1\n",
    "                if (len(word_1.annotations) > 1 or len(word_2.annotations) > 1):\n",
    "                    words_to_disambiguate += 1\n",
    "                    if len(word_3.annotations) == 1:\n",
    "                        words_disambiguated += 1\n",
    "                        if word_3.annotations[0]['full_match']:\n",
    "                            correctly_disambiguated += 1\n",
    "                    if word_3.annotations[0]['full_match']:\n",
    "                        correct_words_all += 1\n",
    "                if word_3.annotations[0]['full_match']:\n",
    "                    correct_analyses_total_after_disamb += 1\n",
    "        words_total += len( morph_0_diff )\n",
    "    print('='*80)\n",
    "    print( ' Words that needed disambiguation:               ', words_to_disambiguate, '/', words_total )\n",
    "    print( '   Incorrectly disambiguated:                    ', (words_disambiguated-correctly_disambiguated), '/', words_to_disambiguate, '   {:.02f}%'.format(((words_disambiguated-correctly_disambiguated)/words_to_disambiguate)*100.0) )\n",
    "    print( '   Correctly disambiguated:                      ', correctly_disambiguated, '/', words_to_disambiguate, '   {:.02f}%'.format((correctly_disambiguated/words_to_disambiguate)*100.0) )\n",
    "    print( '   Disambiguation attempts:                      ', words_disambiguated, '/', words_to_disambiguate, '   {:.02f}%'.format((words_disambiguated/words_to_disambiguate)*100.0) )\n",
    "    print()\n",
    "    print( '   Correct words (including undisambiguated):    ', correct_words_all, '/', words_to_disambiguate, '   {:.02f}%'.format((correct_words_all/words_to_disambiguate)*100.0) )\n",
    "    print('='*80)\n",
    "    print( ' VM words alignable to UD morph words (before disamb): ', correct_analyses_total_before_disamb,'/', words_total, '   {:.02f}%'.format((correct_analyses_total_before_disamb/words_total)*100.0) )\n",
    "    print( ' VM words alignable to UD morph words  (after disamb): ', correct_analyses_total_after_disamb,'/', words_total, '   {:.02f}%'.format((correct_analyses_total_after_disamb/words_total)*100.0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And apply the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Words that needed disambiguation:                9851 / 27286\n",
      "   Incorrectly disambiguated:                     900 / 9851    9.14%\n",
      "   Correctly disambiguated:                       6526 / 9851    66.25%\n",
      "   Disambiguation attempts:                       7426 / 9851    75.38%\n",
      "\n",
      "   Correct words (including undisambiguated):     8937 / 9851    90.72%\n",
      "================================================================================\n",
      " VM words alignable to UD morph words (before disamb):  26458 / 27286    96.97%\n",
      " VM words alignable to UD morph words  (after disamb):  25544 / 27286    93.62%\n"
     ]
    }
   ],
   "source": [
    "# get training part of the corpus\n",
    "#evaluation_texts = [text for text in loaded_texts if 'train' in text.meta['file']]\n",
    "\n",
    "# ... or evaluate on all texts\n",
    "evaluation_texts = loaded_texts\n",
    "\n",
    "eval_disambiguation_of_all_words( evaluation_texts, 'morph_0_diff_layer', 'morph_0_diff_layer', 'morph_1_diff_layer' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vabamorf's analysis and disambiguation with spelling suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = 'UD_Estonian-EWT-master'\n",
    "\n",
    "import os, os.path\n",
    "from ewtb_ud_utils import load_EWTB_ud_file_with_corrections\n",
    "\n",
    "# Load corpus files with corrections\n",
    "ud_layer_name = 'ud_syntax'\n",
    "loaded_texts  = []\n",
    "for fname in os.listdir( eval_data_dir ):\n",
    "    if fname.endswith('.conllu'):\n",
    "        fpath = os.path.join( eval_data_dir, fname )\n",
    "        text = load_EWTB_ud_file_with_corrections( fpath, ud_layer_name )\n",
    "        text.meta['file'] = fname\n",
    "        loaded_texts.append( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VMSpellingSuggestionsTagger\n",
    "\n",
    "Make a tagger that creates a special words layer containing spelling suggestions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tahax</td>\n",
       "      <td>taha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>tahaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>tahad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>assju</td>\n",
       "      <td>asju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>assjõu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='normalized_words', attributes=('normalized_form',), spans=SL[Span('Ma', [{'normalized_form': None}]),\n",
       "Span('tahax', [{'normalized_form': 'taha'}, {'normalized_form': 'tahaks'}, {'normalized_form': 'tahad'}]),\n",
       "Span('teada', [{'normalized_form': None}]),\n",
       "Span('assju', [{'normalized_form': 'asju'}, {'normalized_form': 'assjõu'}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Annotation, ElementaryBaseSpan\n",
    "from estnltk.layer.layer import Layer\n",
    "from estnltk.taggers import Tagger\n",
    "from estnltk.vabamorf import morf as vm\n",
    "from estnltk.taggers.morph_analysis.morf_common import _get_word_texts\n",
    "\n",
    "class VMSpellingSuggestionsTagger(Tagger):\n",
    "    '''Creates normalized_words layer which contains spelling suggestions from Vabamorf's spellchecker.'''\n",
    "    conf_param = []\n",
    "    output_attributes = []\n",
    "    \n",
    "    def __init__(self, words_layer='words', output_layer='normalized_words'):\n",
    "        self.input_layers = [words_layer]\n",
    "        self.output_layer = output_layer\n",
    "        self.output_attributes = ('normalized_form',)\n",
    "    \n",
    "    def _make_layer(self, text, layers, status):\n",
    "        normalzed_words = Layer(name=self.output_layer,\n",
    "                                attributes=self.output_attributes,\n",
    "                                text_object=text,\n",
    "                                ambiguous=True)\n",
    "        words_layer = layers[self.input_layers[0]]\n",
    "        for word in words_layer:\n",
    "            if 'normalized_form' in words_layer.attributes:\n",
    "                word_texts = _get_word_texts(word)\n",
    "            else:\n",
    "                word_texts = [word.text]\n",
    "            suggestions = set()\n",
    "            for word_text in word_texts:\n",
    "                spell_check_result = vm.spellcheck([word_text], suggestions=True)\n",
    "                # Check if we have a misspelled word with suggestions\n",
    "                for item in spell_check_result:\n",
    "                    if not item[\"spelling\"] and len(item[\"suggestions\"]) > 0:\n",
    "                        for new_suggestion in item[\"suggestions\"]:\n",
    "                            if new_suggestion not in suggestions:\n",
    "                                suggestions.add( new_suggestion )                \n",
    "            if suggestions:\n",
    "                for suggestion in suggestions:\n",
    "                    normalzed_words.add_annotation( word.base_span, normalized_form=suggestion )\n",
    "            else:\n",
    "                normalzed_words.add_annotation( word.base_span, normalized_form=None )\n",
    "        return normalzed_words\n",
    "\n",
    "\n",
    "test_text = Text('Ma tahax teada assju.')\n",
    "test_text.tag_layer(['words'])\n",
    "VMSpellingSuggestionsTagger().tag(test_text).normalized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply VMSpellingSuggestionsTagger on the input corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_suggestor = VMSpellingSuggestionsTagger()\n",
    "for text in loaded_texts:\n",
    "    spelling_suggestor.tag( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. No spelling suggestions + Vabamorf's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_0')\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_0')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_0', ud_layer_name, 'morph_0_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spelling suggestions + Vabamorf's analysis only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_1' == VabamorfAnalyzer + PostMorphAnalysisTagger\n",
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_1',\n",
    "                               input_words_layer=spelling_suggestor.output_layer)\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_1')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_1', ud_layer_name, 'morph_1_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spelling suggestions + Vabamorf's analysis with disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_2' == VabamorfTagger\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "\n",
    "vm_tagger = VabamorfTagger(output_layer='morph_2',\n",
    "                           input_words_layer=spelling_suggestor.output_layer)\n",
    "for text in loaded_texts:\n",
    "    vm_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_2', ud_layer_name, 'morph_2_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Vabamorf's analysis and disambiguation after spelling suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Words that needed disambiguation:                10029 / 27286\n",
      "   Incorrectly disambiguated:                     1112 / 10029    11.09%\n",
      "   Correctly disambiguated:                       6489 / 10029    64.70%\n",
      "   Disambiguation attempts:                       7601 / 10029    75.79%\n",
      "\n",
      "   Correct words (including undisambiguated):     8899 / 10029    88.73%\n",
      "================================================================================\n",
      " VM words alignable to UD morph words (before disamb):  26637 / 27286    97.62%\n",
      " VM words alignable to UD morph words  (after disamb):  25418 / 27286    93.15%\n"
     ]
    }
   ],
   "source": [
    "# get training part of the corpus\n",
    "#evaluation_texts = [text for text in loaded_texts if 'train' in text.meta['file']]\n",
    "\n",
    "# ... or evaluate on all texts\n",
    "evaluation_texts = loaded_texts\n",
    "\n",
    "eval_disambiguation_of_all_words( evaluation_texts, 'morph_0_diff_layer', 'morph_1_diff_layer', 'morph_2_diff_layer' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, define a function for a fine-grained statistics about disambiguation quality only on normalized words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers.morph_analysis.morf_common import _get_word_texts\n",
    "\n",
    "def eval_disambiguation_of_normalized_words( texts, normalized_words_layer, \n",
    "                                                    morph_1_diff_layer_name,\n",
    "                                                    morph_2_diff_layer_name ):\n",
    "    '''Evaluates the disambiguation quality (correctly vs incorrectly disambiguated) only on normalized words of the corpus.\n",
    "    '''\n",
    "    words_total = 0\n",
    "    words_with_normalization = 0\n",
    "    words_with_normalization_aligned_before_disamb = 0\n",
    "    words_with_normalization_aligned_after_disamb  = 0\n",
    "    for text in texts:\n",
    "        norm_words   = text[normalized_words_layer]\n",
    "        morph_1_diff = text[morph_1_diff_layer_name]\n",
    "        morph_2_diff = text[morph_2_diff_layer_name]\n",
    "        assert len( morph_1_diff ) == len( norm_words )\n",
    "        assert len( morph_1_diff ) == len( morph_2_diff )\n",
    "        for norm_word, word_2, word_3 in zip(norm_words, morph_1_diff, morph_2_diff):\n",
    "            w_texts = _get_word_texts(norm_word)\n",
    "            if len(w_texts) > 1 or (len(w_texts) == 1 and w_texts[0] != norm_word.text):\n",
    "                words_with_normalization += 1\n",
    "                if word_2.annotations[0]['full_match']:\n",
    "                    words_with_normalization_aligned_before_disamb += 1\n",
    "                if word_3.annotations[0]['full_match']:\n",
    "                    words_with_normalization_aligned_after_disamb += 1        \n",
    "        words_total += len( morph_1_diff )\n",
    "    print('='*80)\n",
    "    print( ' Only words with normalizations (spelling suggestions): ', words_with_normalization, '/', words_total )\n",
    "    print( '   Correctly analysed (without disambiguation):         ', words_with_normalization_aligned_before_disamb, '/', words_with_normalization, '   {:.02f}%'.format((words_with_normalization_aligned_before_disamb/words_with_normalization)*100.0) )\n",
    "    print( '       - Correctly disambiguated:                       ', words_with_normalization_aligned_after_disamb, '/', words_with_normalization, '   {:.02f}%'.format((words_with_normalization_aligned_after_disamb/words_with_normalization)*100.0) )\n",
    "    incorrect = words_with_normalization_aligned_before_disamb - words_with_normalization_aligned_after_disamb\n",
    "    print( '       - Incorrectly disambiguated:                     ', incorrect, '/', words_with_normalization, '   {:.02f}%'.format((incorrect/words_with_normalization)*100.0) )\n",
    "    norm_words_no_ud_match = words_with_normalization - words_with_normalization_aligned_before_disamb\n",
    "    print( '   Word\\'s analyses cannot be matched to UD word\\'s:      ', norm_words_no_ud_match, '/', words_with_normalization, '   {:.02f}%'.format((norm_words_no_ud_match/words_with_normalization)*100.0) )\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And evaluate disambiguation only on normalized words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Only words with normalizations (spelling suggestions):  637 / 27286\n",
      "   Correctly analysed (without disambiguation):          187 / 637    29.36%\n",
      "       - Correctly disambiguated:                        151 / 637    23.70%\n",
      "       - Incorrectly disambiguated:                      36 / 637    5.65%\n",
      "   Word's analyses cannot be matched to UD word's:       450 / 637    70.64%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get training part of the corpus\n",
    "#evaluation_texts = [text for text in loaded_texts if 'train' in text.meta['file']]\n",
    "\n",
    "# ... or evaluate on all texts\n",
    "evaluation_texts = loaded_texts\n",
    "\n",
    "eval_disambiguation_of_normalized_words( evaluation_texts, spelling_suggestor.output_layer, 'morph_1_diff_layer', 'morph_2_diff_layer' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Measurements made on training & test parts of the EWTB corpus\n",
    "    \n",
    "    A) Vabamorf's analysis & disambiguation (baseline: no spelling corrections)\n",
    "    ================================================================================\n",
    "     Words that needed disambiguation:                9851 / 27286\n",
    "       Incorrectly disambiguated:                      900 / 9851     9.14%\n",
    "       Correctly disambiguated:                       6526 / 9851    66.25%\n",
    "       Disambiguation attempts:                       7426 / 9851    75.38%\n",
    "\n",
    "       Correct words (including undisambiguated):     8937 / 9851    90.72%\n",
    "    ================================================================================\n",
    "     VM words alignable to UD morph words (before disamb):  26458 / 27286    96.97%\n",
    "     VM words alignable to UD morph words  (after disamb):  25544 / 27286    93.62%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    B) Vabamorf's analysis & disambiguation on words with spelling suggestions\n",
    "    ================================================================================\n",
    "     Words that needed disambiguation:                10029 / 27286\n",
    "       Incorrectly disambiguated:                     1112 / 10029    11.09%\n",
    "       Correctly disambiguated:                       6489 / 10029    64.70%\n",
    "       Disambiguation attempts:                       7601 / 10029    75.79%\n",
    "\n",
    "       Correct words (including undisambiguated):     8899 / 10029    88.73%\n",
    "    ================================================================================\n",
    "     VM words alignable to UD morph words (before disamb):  26637 / 27286    97.62%\n",
    "     VM words alignable to UD morph words  (after disamb):  25418 / 27286    93.15%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     ================================================================================\n",
    "       Only words with normalizations (spelling suggestions):  637 / 27286\n",
    "         Correctly analysed (without disambiguation):          187 / 637    29.36%\n",
    "             - Correctly disambiguated:                        151 / 637    23.70%\n",
    "             - Incorrectly disambiguated:                       36 / 637     5.65%\n",
    "         Word's analyses cannot be matched to UD word's:       450 / 637    70.64%\n",
    "     ================================================================================\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
