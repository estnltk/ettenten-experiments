{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Vabamorf's disambiguation on spellchecker's suggestions\n",
    "\n",
    "In this small experiment, we use Vabamorf's spellchecker to add _**multiple normalized forms** to the **words layer**_, and examine, how this increased ambiguity affects the quality of Vabamorf's _disambiguation_ in EstNLTK.\n",
    "\n",
    "We use EstNLTK's version 1.6.4beta (from the commit [52c921eb3d](https://github.com/estnltk/estnltk/tree/52c921eb3d06ebc0976c0dac84bc9b9f72b0491e)), and evaluate tools on the Estonian Web Treebank (EWTB) corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Estonian Web Treebank corpus\n",
    "\n",
    "You can download the UD format EWTB corpus from here: https://github.com/UniversalDependencies/UD_Estonian-EWT/ (exact commit: [6cd4d14](https://github.com/UniversalDependencies/UD_Estonian-EWT/tree/6cd4d1480c1f3dc89bcdddab56f04dc51bfa8b48))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = 'UD_Estonian-EWT-master'\n",
    "\n",
    "import os, os.path\n",
    "from ewtb_ud_utils import load_EWTB_ud_file_with_corrections\n",
    "\n",
    "# Load corpus files with corrections\n",
    "ud_layer_name = 'ud_syntax'\n",
    "loaded_texts  = []\n",
    "for fname in os.listdir( eval_data_dir ):\n",
    "    if fname.endswith('.conllu'):\n",
    "        fpath = os.path.join( eval_data_dir, fname )\n",
    "        text = load_EWTB_ud_file_with_corrections( fpath, ud_layer_name )\n",
    "        text.meta['file'] = fname\n",
    "        loaded_texts.append( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vabamorf's analysis and disambiguation (baseline: no spelling suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. No spelling suggestions + Vabamorf's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_0' == VabamorfAnalyzer + PostMorphAnalysisTagger\n",
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_0')\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_0')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_0', ud_layer_name, 'morph_0_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No spelling suggestions + Vabamorf's analysis with disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_1' == VabamorfTagger\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "\n",
    "vm_tagger = VabamorfTagger(output_layer='morph_1',\n",
    "                           input_words_layer='words')\n",
    "for text in loaded_texts:\n",
    "    vm_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_1', ud_layer_name, 'morph_1_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Vabamorf's analysis and disambiguation (baseline: no spelling suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Words that needed disambiguation:                9852 / 27286\n",
      "   Incorrectly disambiguated:                     867 / 9852    8.80%\n",
      "   Correctly disambiguated:                       6520 / 9852    66.18%\n",
      "   Disambiguation attempts:                       7387 / 9852    74.98%\n",
      "\n",
      "   Correct words (including undisambiguated):     8938 / 9852    90.72%\n",
      "================================================================================\n",
      " VM words alignable to UD morph words (before disamb):  26458 / 27286    96.97%\n",
      " VM words alignable to UD morph words  (after disamb):  25544 / 27286    93.62%\n"
     ]
    }
   ],
   "source": [
    "from ewtb_ud_utils import eval_disambiguation_of_all_words\n",
    "\n",
    "# get training part of the corpus\n",
    "#evaluation_texts = [text for text in loaded_texts if 'train' in text.meta['file']]\n",
    "\n",
    "# ... or evaluate on all texts\n",
    "evaluation_texts = loaded_texts\n",
    "\n",
    "eval_disambiguation_of_all_words( evaluation_texts, 'morph_0_diff_layer', 'morph_0_diff_layer', 'morph_1_diff_layer' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vabamorf's analysis and disambiguation with spelling suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = 'UD_Estonian-EWT-master'\n",
    "\n",
    "import os, os.path\n",
    "from ewtb_ud_utils import load_EWTB_ud_file_with_corrections\n",
    "\n",
    "# Load corpus files with corrections\n",
    "ud_layer_name = 'ud_syntax'\n",
    "loaded_texts  = []\n",
    "for fname in os.listdir( eval_data_dir ):\n",
    "    if fname.endswith('.conllu'):\n",
    "        fpath = os.path.join( eval_data_dir, fname )\n",
    "        text = load_EWTB_ud_file_with_corrections( fpath, ud_layer_name )\n",
    "        text.meta['file'] = fname\n",
    "        loaded_texts.append( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VMSpellingSuggestionsTagger\n",
    "\n",
    "Make a tagger that creates a special words layer containing spelling suggestions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tahax</td>\n",
       "      <td>tahax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>tahaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>tahad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>taha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>assju</td>\n",
       "      <td>assju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>asju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>assjõu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='normalized_words', attributes=('normalized_form',), spans=SL[Span('Ma', [{'normalized_form': None}]),\n",
       "Span('tahax', [{'normalized_form': 'tahax'}, {'normalized_form': 'tahaks'}, {'normalized_form': 'tahad'}, {'normalized_form': 'taha'}]),\n",
       "Span('teada', [{'normalized_form': None}]),\n",
       "Span('assju', [{'normalized_form': 'assju'}, {'normalized_form': 'asju'}, {'normalized_form': 'assjõu'}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Annotation, ElementaryBaseSpan\n",
    "from estnltk.layer.layer import Layer\n",
    "from estnltk.taggers import Tagger\n",
    "from estnltk.vabamorf import morf as vm\n",
    "from estnltk.taggers.morph_analysis.morf_common import _get_word_texts\n",
    "\n",
    "class VMSpellingSuggestionsTagger(Tagger):\n",
    "    '''Creates normalized_words layer which contains spelling suggestions from Vabamorf's spellchecker.'''\n",
    "    conf_param = ['keep_original_word_text']\n",
    "    output_attributes = []\n",
    "    \n",
    "    def __init__(self, words_layer='words', output_layer='normalized_words', keep_original_word_text=True):\n",
    "        self.input_layers = [words_layer]\n",
    "        self.output_layer = output_layer\n",
    "        self.output_attributes = ('normalized_form',)\n",
    "        self.keep_original_word_text = keep_original_word_text\n",
    "    \n",
    "    def _make_layer(self, text, layers, status):\n",
    "        normalzed_words = Layer(name=self.output_layer,\n",
    "                                attributes=self.output_attributes,\n",
    "                                text_object=text,\n",
    "                                ambiguous=True)\n",
    "        words_layer = layers[self.input_layers[0]]\n",
    "        for word in words_layer:\n",
    "            if 'normalized_form' in words_layer.attributes:\n",
    "                word_texts = _get_word_texts(word)\n",
    "            else:\n",
    "                word_texts = [word.text]\n",
    "            suggestions = set()\n",
    "            for word_text in word_texts:\n",
    "                spell_check_result = vm.spellcheck([word_text], suggestions=True)\n",
    "                # Check if we have a misspelled word with suggestions\n",
    "                for item in spell_check_result:\n",
    "                    if not item[\"spelling\"] and len(item[\"suggestions\"]) > 0:\n",
    "                        for new_suggestion in item[\"suggestions\"]:\n",
    "                            if new_suggestion not in suggestions:\n",
    "                                suggestions.add( new_suggestion )                \n",
    "            if suggestions:\n",
    "                if self.keep_original_word_text:\n",
    "                    # (+) Pros of keeping original word text:\n",
    "                    #     1) spellchecker may suggest that proper nouns, such as 'Rammstein' and 'Erasmuse',\n",
    "                    #        are wrong, but morph analysis guesser can actually analyse these reasonably \n",
    "                    #        well;\n",
    "                    #     2) spellchecker may suggest that nouns, such as 'krossikal' and 'reformarite',\n",
    "                    #        are wrong, but morph analysis guesser can actually analyse these reasonably \n",
    "                    #        well;\n",
    "                    #     3) spellchecker may suggest that adverbs, such as 'tegelt', are wrong, but morph \n",
    "                    #        analysis guesser can actually analyse these reasonably well;\n",
    "                    #     4) spellchecker may suggest corrections to interjections, such as 'oih' and 'Mhh',\n",
    "                    #        which actually need no corrections / normalizations in their lemmas;\n",
    "                    # (-) Cons of keeping original word text:\n",
    "                    #     Places where UD treebank's manual corrections are inconsistent or wrong may\n",
    "                    #     become invisible, and will be counted as \"correct matches\", although they \n",
    "                    #     actually are not. Examples:\n",
    "                    #     1) lowercase propernames, such as 'tallinnast' or 'iklat', will match, because \n",
    "                    #        their UD xpostag is 'S', although correct should be 'H';\n",
    "                    #     2) adjectives, such as 'krõvisevaid' and 'kõkuvaid', will match, because their\n",
    "                    #        UD lemmas have not been corrected ( 'krõvisevaid' => 'krõvisev', but correct \n",
    "                    #        is 'krõbisev'; 'kõkuvaid' => 'kõkuv', but is correct: 'kõikuv');\n",
    "                    #     3) nouns, such as 'konsentratsioon', will match because of incorrect UD lemmas\n",
    "                    #        ('konsentratsioon' => 'konsentratsioon', although correct is 'kontsentratsioon');\n",
    "                    if word.text not in suggestions:\n",
    "                        normalzed_words.add_annotation( word.base_span, normalized_form=word.text )\n",
    "                for suggestion in suggestions:\n",
    "                    normalzed_words.add_annotation( word.base_span, normalized_form=suggestion )\n",
    "            else:\n",
    "                normalzed_words.add_annotation( word.base_span, normalized_form=None )\n",
    "        return normalzed_words\n",
    "\n",
    "\n",
    "test_text = Text('Ma tahax teada assju.')\n",
    "test_text.tag_layer(['words'])\n",
    "VMSpellingSuggestionsTagger().tag(test_text).normalized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply VMSpellingSuggestionsTagger on the input corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_suggestor = VMSpellingSuggestionsTagger()\n",
    "for text in loaded_texts:\n",
    "    spelling_suggestor.tag( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. No spelling suggestions + Vabamorf's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_0')\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_0')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_0', ud_layer_name, 'morph_0_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spelling suggestions + Vabamorf's analysis only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_1' == VabamorfAnalyzer + PostMorphAnalysisTagger\n",
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_1',\n",
    "                               input_words_layer=spelling_suggestor.output_layer)\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_1')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_1', ud_layer_name, 'morph_1_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spelling suggestions + Vabamorf's analysis with disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_2' == VabamorfTagger\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "\n",
    "vm_tagger = VabamorfTagger(output_layer='morph_2',\n",
    "                           input_words_layer=spelling_suggestor.output_layer)\n",
    "for text in loaded_texts:\n",
    "    vm_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_2', ud_layer_name, 'morph_2_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Vabamorf's analysis and disambiguation after spelling suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Words that needed disambiguation:                10158 / 27286\n",
      "   Incorrectly disambiguated:                     958 / 10158    9.43%\n",
      "   Correctly disambiguated:                       6488 / 10158    63.87%\n",
      "   Disambiguation attempts:                       7446 / 10158    73.30%\n",
      "\n",
      "   Correct words (including undisambiguated):     9081 / 10158    89.40%\n",
      "================================================================================\n",
      " VM words alignable to UD morph words (before disamb):  26637 / 27286    97.62%\n",
      " VM words alignable to UD morph words  (after disamb):  25560 / 27286    93.67%\n"
     ]
    }
   ],
   "source": [
    "from ewtb_ud_utils import eval_disambiguation_of_all_words\n",
    "\n",
    "# get training part of the corpus\n",
    "#evaluation_texts = [text for text in loaded_texts if 'train' in text.meta['file']]\n",
    "\n",
    "# ... or evaluate on all texts\n",
    "evaluation_texts = loaded_texts\n",
    "\n",
    "eval_disambiguation_of_all_words( evaluation_texts, 'morph_0_diff_layer', 'morph_1_diff_layer', 'morph_2_diff_layer' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And get a fine-grained statistics about disambiguation quality only on normalized words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Only words with normalizations (spelling suggestions):  637 / 27286\n",
      "   Correctly analysed (without disambiguation):          484 / 637    75.98%\n",
      "       - Correctly disambiguated:                        288 / 637    45.21%\n",
      "       - Incorrectly disambiguated:                      196 / 637    30.77%\n",
      "   Word's analyses cannot be matched to UD word's:       153 / 637    24.02%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ewtb_ud_utils import eval_disambiguation_of_normalized_words\n",
    "\n",
    "# get training part of the corpus\n",
    "#evaluation_texts = [text for text in loaded_texts if 'train' in text.meta['file']]\n",
    "\n",
    "# ... or evaluate on all texts\n",
    "evaluation_texts = loaded_texts\n",
    "\n",
    "eval_disambiguation_of_normalized_words( evaluation_texts, spelling_suggestor.output_layer, 'morph_1_diff_layer', 'morph_2_diff_layer' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Measurements made on training & test parts of the EWTB corpus\n",
    "    \n",
    "    A) Vabamorf's analysis & disambiguation (baseline: no spelling corrections)\n",
    "    ================================================================================\n",
    "     Words that needed disambiguation:                9852 / 27286\n",
    "       Incorrectly disambiguated:                     867 / 9852      8.80%\n",
    "       Correctly disambiguated:                       6520 / 9852    66.18%\n",
    "       Disambiguation attempts:                       7387 / 9852    74.98%\n",
    "\n",
    "       Correct words (including undisambiguated):     8938 / 9852    90.72%\n",
    "    ================================================================================\n",
    "     VM words alignable to UD morph words (before disamb):  26458 / 27286    96.97%\n",
    "     VM words alignable to UD morph words  (after disamb):  25544 / 27286    93.62%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    B) Vabamorf's analysis & disambiguation on words with spelling suggestions    \n",
    "    ================================================================================\n",
    "     Words that needed disambiguation:                10158 / 27286\n",
    "       Incorrectly disambiguated:                     958 / 10158      9.43%\n",
    "       Correctly disambiguated:                       6488 / 10158    63.87%\n",
    "       Disambiguation attempts:                       7446 / 10158    73.30%\n",
    "\n",
    "       Correct words (including undisambiguated):     9081 / 10158    89.40%\n",
    "    ================================================================================\n",
    "     VM words alignable to UD morph words (before disamb):  26637 / 27286    97.62%\n",
    "     VM words alignable to UD morph words  (after disamb):  25560 / 27286    93.67%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     ================================================================================\n",
    "      Only words with normalizations (spelling suggestions):  637 / 27286\n",
    "        Correctly analysed (without disambiguation):          484 / 637    75.98%\n",
    "            - Correctly disambiguated:                        288 / 637    45.21%\n",
    "            - Incorrectly disambiguated:                      196 / 637    30.77%\n",
    "        Word's analyses cannot be matched to UD word's:       153 / 637    24.02%\n",
    "      ================================================================================"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
