{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParagraphWebLanguageScoreRetagger\n",
    "\n",
    "ParagraphWebLanguageScoreRetagger is a retagger for identifying texts or parts of texts, that represent the usage of web language. It detects certain features describing web language in all the paragraphs of a text and attaches scores found to paragraph layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from paragraphweblanguagescoreretagger import ParagraphWebLanguageScoreRetagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Retagger</h4>\n",
       "Retagger for detecting web language features in text. Web language features will be marked as attributes of the paragraphs layer.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ParagraphWebLanguageScoreRetagger</td>\n",
       "      <td>paragraphs</td>\n",
       "      <td>('word_count', 'emoticons', 'missing_commas', 'unknown_words', 'letter_reps', 'no_spaces', 'capital_letters', 'foreign_letters', 'ignored_capital', 'incorrect_spaces')</td>\n",
       "      <td>('paragraphs', 'words', 'compound_tokens', 'clauses')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>use_unknown_words</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_emoticons</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_letter_reps</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_punct_reps</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_capital_letters</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_missing_commas</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_ignored_capital</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_no_spaces</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_incorrect_spaces</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_foreign_letters</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_tagger</th>\n",
       "      <td>RegexTagger(()-&gt;web_language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clause_segmenter</th>\n",
       "      <td>ClauseSegmenter(('words', 'sentences', 'morph_analysis')-&gt;ignore_missing_commas_clauses)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vabamorf_tagger</th>\n",
       "      <td>VabamorfTagger(disambiguate=False, guess=False, phonetic=False, postanalysis_tag ..., type: &lt;class 'estnltk.taggers.morph_analysis.morf.VabamorfTagger'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ParagraphWebLanguageScoreRetagger(use_unknown_words=True, use_emoticons=True, use_letter_reps=True, use_punct_reps=False, use_capital_letters=True, use_missing_commas=True, use_ignored_capital=True, use_no_spaces=True, use_incorrect_spaces=True, use_foreign_letters=True, regex_tagger=RegexTagger(()->web_language), clause_segmenter=ClauseSegmenter(('words', 'sentences', 'morph_analysis')->ignore_missing_commas_clauses), vabamorf_tagger=VabamorfTagger(disambiguate=False, guess=False, phonetic=False, postanalysis_tagger=PostMorphAnalysisTagger, propername=False))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weblang_score_retagger=  ParagraphWebLanguageScoreRetagger()\n",
    "weblang_score_retagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying ParagraphWebLanguageScoreRetagger, the input Text object must have layers \"paragraphs\", \"words\", \"compound_tokens\" and \"clauses\".\n",
    "\n",
    "Texts can be analysed based on 10 different features that describe the usage of web language. Flags of these features can be set True or False, by default 9 features are used. \n",
    "<br>\n",
    "For example, ParagraphWebLanguageScoreRetagger(use_punct_reps=True) activates the feature **punct_reps** that by default is set to False.\n",
    "\n",
    "#### Flags and what they detect:\n",
    "\n",
    "- **use_unknown_words** -- words that are unknown to the morphological analyser (if morphological analysis without guessing is used)\n",
    "<br>\n",
    "- **use_emoticons** -- emoticons, e.g. *:D, :)*\n",
    "<br>\n",
    "- **use_letter_reps** -- same letter more than twice in a row, e.g. *jaaaaa*\n",
    "<br>\n",
    "- **use_punct_reps** -- punctuation marks multiple times (except a dot), e.g. *!!!!!!*\n",
    "<br>\n",
    "- **use_capital_letters** -- longer parts of text in capital letters, e.g. *MINE METSA! KUHU SA LÄHED?*\n",
    "<br>\n",
    "- **use_missing_commas** -- missing commas\n",
    "<br>\n",
    "- **use_ignored_capital** -- lowercase letters used instead of capital letters in sentence-initial positions, e.g. *Tere? kuidas läheb?*\n",
    "<br>\n",
    "- **use_no_spaces** -- no spaces after punctuation marks, e.g. *Ilm on ilus.Päike paistab.*\n",
    "<br>\n",
    "- **use_incorrect_spaces** -- incorrect spaces before and after punctuation marks, e.g. *Tore ! Mulle meeldib.*\n",
    "<br>\n",
    "- **use_foreign_letters** -- usage of foreign letters inside (non-capitalized) words, e.g. *ma ei viici yksi*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example #1\n",
    "\n",
    "Let's first try ParagraphWebLanguageScoreRetagger on a string consisting of 4 sentences and 2 paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tšau ! mis teed???</br></br></br>Kas sa kinno ei viitsi minna? mul on niiii igav et ma lähen hulluks varsti!</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Metadata</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>whole_text_score</td>\n",
       "      <td>0.272727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td>word_count, emoticons, missing_commas, unknown_words, letter_reps, no_spaces, capital_letters, foreign_letters, ignored_capital, incorrect_spaces</td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tšau ! mis teed???\\n\\n\\nKas sa kinno ei viitsi minna? mul on niiii igav et ma lähen hulluks varsti!')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=Text('''Tšau ! mis teed???\n",
    "\n",
    "\n",
    "Kas sa kinno ei viitsi minna? mul on niiii igav et ma lähen hulluks varsti!''')\n",
    "# Add required layers\n",
    "text.tag_layer([\"compound_tokens\", \"words\", \"paragraphs\",\"clauses\"])\n",
    "# Add annotation (adds scores of attributes of web language to paragraph layer)\n",
    "weblang_score_retagger.retag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraph 1 : Tšau ! mis teed???\n",
      "Attribute: word_count --> Score: 5\n",
      "Attribute: ignored_capital --> Score: 1\n",
      "Attribute: incorrect_spaces --> Score: 1\n",
      "---\n",
      "Paragraph 2 : Kas sa kinno ei viitsi minna? mul on niiii igav et ma lähen hulluks varsti!\n",
      "Attribute: word_count --> Score: 17\n",
      "Attribute: missing_commas --> Score: 1\n",
      "Attribute: unknown_words --> Score: 1\n",
      "Attribute: letter_reps --> Score: 1\n",
      "Attribute: ignored_capital --> Score: 1\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for parag in range(len(text[\"paragraphs\"])):\n",
    "    print(\"Paragraph\",parag+1,\":\",text.paragraphs[parag].enclosing_text)\n",
    "    for i in text[\"paragraphs\"].attributes:\n",
    "        if text.paragraphs[i][parag] > 0:\n",
    "            print(\"Attribute:\",i,\"--> Score:\",text.paragraphs[i][parag])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The received output above shows us, that the text has 2 paragraphs, ParagraphWebLanguageScoreRetagger has detected a number of features from text and added the scores to paragraph layer.\n",
    "<br>\n",
    "Note that feature **word_count** is not defined as a flag -- it is used for calculating whole text score that is always calculated and added."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a flag of a feature is set to True (whether by default or not), but no such features are detected in the text, 0 will be added to paragraph layer as a score of this feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.paragraphs[0]['missing_commas'] # e.g. first paragraph had no missing commas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**whole_text_score** - all the scores of features attached to paragraph layer are summed and divided by the total number of words used in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2727272727272727"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.meta[\"whole_text_score\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example #2\n",
    "\n",
    "ParagraphWebLanguageScoreRetagger helps to compare and categorize different texts -- if one gets a 0 as a whole_text_score and the other 0.2727, for example, as the previous example, we might say the first text can possibly be a canonical language text and second one a non-canonical language text.\n",
    "\n",
    "We can test the idea on different text files that already have been categorized as either canonical or non-canonical texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical text:\n",
      "\n",
      "Videopäevik: Küllap ka nõid on kunagi armastanud!\n",
      "\n",
      "Viimasel näitlejakoolitusel Hiiumaal Kärdlas osales ka Publiku videopäeviku pidaja Gert. Kogu maikuu sai hoogu võetud, et hirmust üle saada ja peaaegu õnnestus. Igal filminäitleja koolitusel tehti alguses veidi lõdvestavaid harjutusi ning siis asuti konkreetsete stseenide juurde, mis stsenaariumis kirjas.\n",
      "\n",
      "Meie tänane kangelane pidi koos Brendaga teelt eksima ja sattuma nõia juurde. Hirmust ülesaamiseks sisendas Gert endale, et küllap ka nõid on kunagi armastanud. \n",
      "\n",
      "word_count [9, 44, 27]\n",
      "emoticons [0, 0, 0]\n",
      "missing_commas [0, 0, 0]\n",
      "unknown_words [0, 0, 0]\n",
      "letter_reps [0, 0, 0]\n",
      "no_spaces [0, 0, 0]\n",
      "capital_letters [0, 0, 0]\n",
      "foreign_letters [0, 0, 0]\n",
      "ignored_capital [0, 0, 0]\n",
      "incorrect_spaces [0, 0, 0]\n",
      "whole_text_score: 0.0\n",
      "----------------------\n",
      "\n",
      "Canonical text:\n",
      "\n",
      "Endine Tartu haridusosakonna finantseerimise peaspetsialist Irina Aab sai aastaid tulu ka linnalt sadu tuhandeid kroone teeninud Kersti Võlu Koolituskeskuse koolitajana: ta tegeles ka koolituste korraldamisega.\n",
      "\n",
      "Ainuüksi Tartu linnavalitsuse haridusosakond maksis Kersti Võlu Koolituskeskusele 2009. aastast selle aasta alguseni 334 000 krooni. Kinnitamata andmetel võeti Aabi tänutäheks muu hulgas kaasa ka koolitusreisidele kaugetesse maadesse, kirjutas Tartu Postimees .\n",
      "\n",
      "Postimehe andmetel läks linnavalitsuse sisekontrolli juurdluse kohaselt kahtlasevõitu arvete alla aastate jooksul kaotsi kokku kuni 2,5 miljonit krooni. Osa sellest maksti välja otse linnavalitsuse haridusosakonna kontolt, koolidel oli aga oma eelarve. \n",
      "\n",
      "word_count [27, 33, 34]\n",
      "emoticons [0, 0, 0]\n",
      "missing_commas [0, 0, 0]\n",
      "unknown_words [0, 0, 0]\n",
      "letter_reps [0, 0, 0]\n",
      "no_spaces [0, 0, 0]\n",
      "capital_letters [0, 0, 0]\n",
      "foreign_letters [0, 0, 0]\n",
      "ignored_capital [0, 0, 0]\n",
      "incorrect_spaces [0, 0, 0]\n",
      "whole_text_score: 0.0\n",
      "----------------------\n",
      "\n",
      "Non-canonical text:\n",
      "\n",
      "Saime päranduseks koos õega maja ja korteri. Et kumbki tahtis minnisasja ainuomandisse,vormistasime notaris nn.vahetustehingu et lepingu allkirjastamse hetkest kuulub minule maja ja talle korter.Aga juba kuu aega keeldub too majast välja kolimast, kasutab-kulutab kõike nagu peremees.Plaan temast vabaneda soliidsel moel ei õnnestunud,kuna ühestki tähtajast ei taha kuuldagi.Kuidas käituda,tõsta välja kas on politseid vaja sel juhul?\n",
      "\n",
      "Appi, need sugulaste vahelised riiud on jubedad. ka ise olen omal nahal kogenud. Mine kogu täiega sinna elama, kus seaduswe järgi on sinul õigus ja vaata, kas annab alla.\n",
      "\n",
      "to Sugulane: maja kuulubki mulle,elan seal,pean ülal ka haiget ema,õde aga muudkui ülbab ja laiab-korterissse kuidagi ei kavatse kolida ehkki ise pakkus sellise variandi välja.\n",
      "\n",
      "Ukseluku vahetus aitab enamikel juhtudel. Mõnikord tuleb ka akendele turvakiled peale panna. (trellid võivad ka olla, aga see pole ilus). Eriti keerulistel juhtudel pane ventilatsioonilõõridesse, kanalisatsioonitorudesse ja korstnasse nii suure silmaga terasvõrk, et inimene läbi ei mahuks. \n",
      "\n",
      "word_count [71, 35, 33, 46]\n",
      "emoticons [0, 0, 0, 0]\n",
      "missing_commas [1, 0, 1, 0]\n",
      "unknown_words [4, 2, 5, 0]\n",
      "letter_reps [0, 0, 0, 0]\n",
      "no_spaces [6, 0, 3, 0]\n",
      "capital_letters [0, 0, 0, 0]\n",
      "foreign_letters [0, 1, 0, 0]\n",
      "ignored_capital [0, 1, 0, 0]\n",
      "incorrect_spaces [0, 0, 0, 0]\n",
      "whole_text_score: 0.12972972972972974\n",
      "----------------------\n",
      "\n",
      "Non-canonical text:\n",
      "\n",
      "et ma tahaks vist sammuli tallitesse trenni minna et rääkige et kuidas seal inimesed on ja et kes see treener on et mis nimi et äkki tuleb tuttav ette ja üldse nendest kes trennis käivad ja hobustest ja inimestest et kas seal on sõbralikud inimesed???\n",
      "\n",
      "Ma nüüd läksingi sinna eile käisin esimest korda trennis ja väga tore treener on ja trennikaaskased on ka esmamuljest väga toredad soovitan minna.Ja täna lähen ka sinna trenni.Et kui sa tahad aega kokkuleppida et kuna sinna trenni minna, siis tuleb treenerile helistada ja treeneri number on +372 51 57 447 et siis helista ja lepi treeneriga aeg kokku kuna sa tahaksid trenni minna.Koht on seal ka väga ilus ja tall on väga puhas ja korras.Hobustekohta ei oskagi midagi öelda, sest olen nii vähe alles käinud aga ma sõitsin Bairon-iga ja temaga oli küll väga hea sõita , hobused kellega selletrenniajal sõideti olid kõik ikka suuremad aga väiksemaid peaks seal ka olema.Seal on veel nii et kas võtad viiekorra trenni see maksab 470kr või võtad kümnekorra trenni see maksab 770 kr. aga see kas kümnekorra oma või viiekorra oma tuleb kolmekümne päeva jooksul ära kasutada. Soovitan kindlasti väga hea tall. \n",
      "\n",
      "word_count [46, 161]\n",
      "emoticons [0, 0]\n",
      "missing_commas [3, 4]\n",
      "unknown_words [4, 2]\n",
      "letter_reps [0, 0]\n",
      "no_spaces [0, 5]\n",
      "capital_letters [0, 0]\n",
      "foreign_letters [0, 0]\n",
      "ignored_capital [0, 1]\n",
      "incorrect_spaces [0, 1]\n",
      "whole_text_score: 0.0966183574879227\n",
      "----------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from estnltk.converters import json_to_text\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path = os.path.join(cwd, \"kirjak_vs_mittekirjak_ettenten\") # files taken from a folder \"kirjak_vs_mittekirjak_ettenten\"\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    file_location = os.path.join(path, file)\n",
    "    if \"kirjak__filmitalgud_ee__58638.json\" in file_location or \"mittekirjak__www_lemmik_ee__100692.json\" in file_location \\\n",
    "    or \"kirjak__uudised_err_ee__98236.json\" in file_location or \"mittekirjak__juura_ee__100106.json\" in file_location:\n",
    "        filename=file_location.split(\"\\\\\")[-1]\n",
    "        text = json_to_text(file=file_location)\n",
    "        text.tag_layer([\"compound_tokens\", \"words\", \"paragraphs\",\"clauses\"])\n",
    "        weblang_score_retagger.retag(text) \n",
    "        \n",
    "        if \"mittekirjak\" in filename:\n",
    "            print(\"Non-canonical text:\\n\")\n",
    "            print(text.text,'\\n')\n",
    "        else:\n",
    "            print(\"Canonical text:\\n\")\n",
    "            print(text.text,'\\n')\n",
    "        \n",
    "        for i in text[\"paragraphs\"].attributes:\n",
    "            print(i,text[\"paragraphs\"][i])\n",
    "            \n",
    "        print(\"whole_text_score:\",text.meta[\"whole_text_score\"] )\n",
    "        print(\"----------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonical texts have got whole_text_score as 0 -- no features that describe the usage of web language were found.\n",
    "<br>\n",
    "Non-canonical texts have got whole_text_score as 0.1297 and 0.0966 and as it can be seen on the given output above, different features were detected in all the paragraphs of these texts.\n",
    "<br>\n",
    "The output confirmes that the non-canonical texts included more of such features described than the canonical texts. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
