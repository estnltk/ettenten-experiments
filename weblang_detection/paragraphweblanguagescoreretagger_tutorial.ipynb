{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ParagraphWebLanguageScoreRetagger\n",
    "\n",
    "ParagraphWebLanguageScoreRetagger is a retagger for identifying texts or parts of texts, that represent the usage of web language. It detects certain attributes describing web language in all the paragraphs of a text and attaches scores found to paragraph layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from estnltk import Text\n",
    "from paragraphweblanguagescoreretagger import ParagraphWebLanguageScoreRetagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Retagger</h4>\n",
       "Adds scores of different attributes of web language to paragraph layer.\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>name</th>\n",
       "      <th>output layer</th>\n",
       "      <th>output attributes</th>\n",
       "      <th>input layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>ParagraphWebLanguageScoreRetagger</td>\n",
       "      <td>paragraphs</td>\n",
       "      <td>('word_count', 'emoticons', 'missing_commas', 'unknown_words', 'letter_reps', 'no_spaces', 'capital_letters', 'foreign_letters', 'ignored_capital', 'incorrect_spaces')</td>\n",
       "      <td>('paragraphs', 'words', 'compound_tokens', 'clauses')</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Configuration</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>use_unknown_words</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_emoticons</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_letter_reps</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_punct_reps</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_capital_letters</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_missing_commas</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_ignored_capital</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_no_spaces</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_incorrect_spaces</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_foreign_letters</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regex_tagger</th>\n",
       "      <td>RegexTagger(()-&gt;web_language)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clause_segmenter</th>\n",
       "      <td>ClauseSegmenter(('words', 'sentences', 'morph_analysis')-&gt;ignore_missing_commas_clauses)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vabamorf_tagger</th>\n",
       "      <td>VabamorfTagger(disambiguate=False, guess=False, phonetic=False, postanalysis_tag ..., type: &lt;class 'estnltk.taggers.morph_analysis.morf.VabamorfTagger'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clause_segmenter</th>\n",
       "      <td>ClauseSegmenter(('words', 'sentences', 'morph_analysis')-&gt;ignore_missing_commas_clauses)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vabamorf_tagger</th>\n",
       "      <td>VabamorfTagger(disambiguate=False, guess=False, phonetic=False, postanalysis_tag ..., type: &lt;class 'estnltk.taggers.morph_analysis.morf.VabamorfTagger'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "ParagraphWebLanguageScoreRetagger(use_unknown_words=True, use_emoticons=True, use_letter_reps=True, use_punct_reps=False, use_capital_letters=True, use_missing_commas=True, use_ignored_capital=True, use_no_spaces=True, use_incorrect_spaces=True, use_foreign_letters=True, regex_tagger=RegexTagger(()->web_language), clause_segmenter=ClauseSegmenter(('words', 'sentences', 'morph_analysis')->ignore_missing_commas_clauses), vabamorf_tagger=VabamorfTagger(disambiguate=False, guess=False, phonetic=False, postanalysis_tagger=PostMorphAnalysisTagger, propername=False), clause_segmenter=ClauseSegmenter(('words', 'sentences', 'morph_analysis')->ignore_missing_commas_clauses), vabamorf_tagger=VabamorfTagger(disambiguate=False, guess=False, phonetic=False, postanalysis_tagger=PostMorphAnalysisTagger, propername=False))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weblang_score_retagger=  ParagraphWebLanguageScoreRetagger()\n",
    "weblang_score_retagger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before applying ParagraphWebLanguageScoreRetagger, the input Text object must have layers \"paragraphs\", \"words\", \"compound_tokens\" and \"clauses\".\n",
    "\n",
    "Texts can be analysed based on 10 different attributes that describe the usage of web language. Flags of attributes can be set True or False, by default 9 attributes are used. \n",
    "<br>\n",
    "For example, ParagraphWebLanguageScoreRetagger(use_punct_reps=True) activates the attribute **punct_reps** that by default is set to False.\n",
    "\n",
    "#### Flags and what they detect:\n",
    "\n",
    "- **use_unknown_words** -- words without morphological analysis\n",
    "<br>\n",
    "- **use_emoticons** -- emoticons, eg. *:D, :)*\n",
    "<br>\n",
    "- **use_letter_reps** -- same letter more than twice in a row, eg. *jaaaaa*\n",
    "<br>\n",
    "- **use_punct_reps** -- punctuation marks multiple times (except a dot), eg. *!!!!!!*\n",
    "<br>\n",
    "- **use_capital_letters** -- longer parts of text in capital letters, eg. *MINE METSA! KUHU SA LÄHED?*\n",
    "<br>\n",
    "- **use_missing_commas** -- missing commas\n",
    "<br>\n",
    "- **use_ignored_capital** -- ignored capital letters, eg. *Tere? kuidas läheb?*\n",
    "<br>\n",
    "- **use_no_spaces** -- no spaces after punctuation marks, eg. *Ilm on ilus.Päike paistab.*\n",
    "<br>\n",
    "- **use_incorrect_spaces** -- incorrect spaces before and after punctuation marks, eg. *Tore ! Mulle meeldib.*\n",
    "<br>\n",
    "- **use_foreign_letters** -- foreign letters, eg. *q*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example #1\n",
    "\n",
    "Let's first try ParagraphWebLanguageScoreRetagger on a string consisting of 4 sentences and 2 paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td><div align = \"left\">Tšau ! mis teed???</br></br></br>Kas sa kinno ei viitsi minna? mul on niiii igav et ma lähen hulluks varsti!&quot;</div></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<h4>Metadata</h4>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>whole_text_score</td>\n",
       "      <td>0.217391</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>paragraphs</td>\n",
       "      <td>word_count, emoticons, missing_commas, unknown_words, letter_reps, no_spaces, capital_letters, foreign_letters, ignored_capital, incorrect_spaces</td>\n",
       "      <td>None</td>\n",
       "      <td>sentences</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sentences</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tokens</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>compound_tokens</td>\n",
       "      <td>type, normalized</td>\n",
       "      <td>None</td>\n",
       "      <td>tokens</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clauses</td>\n",
       "      <td>clause_type</td>\n",
       "      <td>None</td>\n",
       "      <td>words</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Text(text='Tšau ! mis teed???\\n\\n\\nKas sa kinno ei viitsi minna? mul on niiii igav et ma lähen hulluks varsti!\"')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=Text('''Tšau ! mis teed???\n",
    "\n",
    "\n",
    "Kas sa kinno ei viitsi minna? mul on niiii igav et ma lähen hulluks varsti!\"''')\n",
    "# Add required layers\n",
    "text.tag_layer([\"compound_tokens\", \"words\", \"paragraphs\",\"clauses\"])\n",
    "# Add annotation (adds scores of attributes of web language to paragraph layer)\n",
    "weblang_score_retagger.retag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute: word_count\n",
      "Score in paragraph 1 : 5\n",
      "Attribute: word_count\n",
      "Score in paragraph 2 : 18\n",
      "---\n",
      "Attribute: emoticons\n",
      "Score in paragraph 1 : 0\n",
      "Attribute: emoticons\n",
      "Score in paragraph 2 : 0\n",
      "---\n",
      "Attribute: missing_commas\n",
      "Score in paragraph 1 : 0\n",
      "Attribute: missing_commas\n",
      "Score in paragraph 2 : 1\n",
      "---\n",
      "Attribute: unknown_words\n",
      "Score in paragraph 1 : 0\n",
      "Attribute: unknown_words\n",
      "Score in paragraph 2 : 0\n",
      "---\n",
      "Attribute: letter_reps\n",
      "Score in paragraph 1 : 0\n",
      "Attribute: letter_reps\n",
      "Score in paragraph 2 : 1\n",
      "---\n",
      "Attribute: no_spaces\n",
      "Score in paragraph 1 : 0\n",
      "Attribute: no_spaces\n",
      "Score in paragraph 2 : 0\n",
      "---\n",
      "Attribute: capital_letters\n",
      "Score in paragraph 1 : 0\n",
      "Attribute: capital_letters\n",
      "Score in paragraph 2 : 0\n",
      "---\n",
      "Attribute: foreign_letters\n",
      "Score in paragraph 1 : 0\n",
      "Attribute: foreign_letters\n",
      "Score in paragraph 2 : 0\n",
      "---\n",
      "Attribute: ignored_capital\n",
      "Score in paragraph 1 : 1\n",
      "Attribute: ignored_capital\n",
      "Score in paragraph 2 : 1\n",
      "---\n",
      "Attribute: incorrect_spaces\n",
      "Score in paragraph 1 : 1\n",
      "Attribute: incorrect_spaces\n",
      "Score in paragraph 2 : 0\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for i in text[\"paragraphs\"].attributes:\n",
    "    for parag in range(len(text[\"paragraphs\"])):\n",
    "        print(\"Attribute:\",i)\n",
    "        print(\"Score in paragraph\",parag+1,\":\",text.paragraphs[i][parag])\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The received output above shows us, that the text has 2 paragraphs, ParagraphWebLanguageScoreRetagger has detected a number of attributes from text and added the scores, even 0 if none was found, to paragraph layer.\n",
    "<br>\n",
    "<br>\n",
    "Note that attribute **word_count** is not defined as a flag -- it is used for calculating whole text score that is always calculated and added.\n",
    "<br>\n",
    "**whole_text_score** - all the scores of attributes attached to paragraph layer are summed and divided by the total number of words used in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21739130434782608"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.meta[\"whole_text_score\"] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Example #2\n",
    "\n",
    "ParagraphWebLanguageScoreRetagger helps to compare and categorize different texts -- if one gets a 0 as a whole_text_score and the other 0.217, for example, as the previous example, we might say the first text can possibly be a canonical language text and second one a non-canonical language text.\n",
    "\n",
    "We can test the idea on two different text files that already have been categorized as either canonical or non-canonical texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Canonical text:\n",
      "word_count [44, 46, 52, 50, 120, 1, 1]\n",
      "emoticons [0, 0, 0, 0, 0, 0, 0]\n",
      "missing_commas [0, 0, 0, 0, 0, 0, 0]\n",
      "unknown_words [0, 0, 0, 0, 0, 0, 0]\n",
      "letter_reps [0, 0, 0, 0, 0, 0, 0]\n",
      "no_spaces [0, 0, 0, 0, 0, 0, 0]\n",
      "capital_letters [0, 0, 0, 0, 0, 0, 0]\n",
      "foreign_letters [0, 0, 0, 0, 0, 0, 0]\n",
      "ignored_capital [0, 0, 0, 0, 0, 0, 0]\n",
      "incorrect_spaces [0, 0, 0, 0, 0, 0, 0]\n",
      "whole_text_score: 0.0\n",
      "----------------\n",
      "Non-canonical text:\n",
      "word_count [63, 82, 77, 62, 81, 64, 81, 80, 56, 64, 100, 63, 76]\n",
      "emoticons [0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "missing_commas [0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "unknown_words [2, 0, 0, 1, 2, 3, 0, 0, 1, 0, 2, 3, 2]\n",
      "letter_reps [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "no_spaces [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 2, 1, 2]\n",
      "capital_letters [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "foreign_letters [1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 3, 0]\n",
      "ignored_capital [0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 4, 0, 0]\n",
      "incorrect_spaces [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1]\n",
      "whole_text_score: 0.05690200210748156\n",
      "----------------\n"
     ]
    }
   ],
   "source": [
    "from estnltk.converters import json_to_text\n",
    "import os\n",
    "\n",
    "cwd = os.getcwd()\n",
    "path = os.path.join(cwd, \"test_files\") # files taken from a folder \"test_files\"\n",
    "\n",
    "for file in os.listdir(path):\n",
    "    file_location = os.path.join(path, file)\n",
    "    if \"json\" in file_location:\n",
    "        filename=file_location.split(\"\\\\\")[-1]\n",
    "        text = json_to_text(file=file_location)\n",
    "        weblang_score_retagger.retag(text) \n",
    "        \n",
    "        if \"mittekirjak\" in filename:\n",
    "            print(\"Non-canonical text:\")\n",
    "        else:\n",
    "            print(\"Canonical text:\")\n",
    "        \n",
    "        for i in text[\"paragraphs\"].attributes:\n",
    "            print(i,text[\"paragraphs\"][i])\n",
    "            \n",
    "        print(\"whole_text_score:\",text.meta[\"whole_text_score\"] )\n",
    "        print(\"----------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canonical text has got whole_text_score as 0 -- no attributes that describe the usage of web language were found.\n",
    "<br>\n",
    "Non-canonical text got whole_text_score as 0.0569 and as it can be seen on the given output above, different attributes were detected in all the 13 paragraphs.\n",
    "<br>\n",
    "The output confirmes that the non-canonical text included more of such attributes described than the canonical text. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
