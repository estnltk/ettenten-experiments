{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of Vabamorf's disambiguation on spellchecker's suggestions\n",
    "\n",
    "In this tiny experiment, we use Vabamorf's spellchecker to add _**multiple normalized forms** to the **words layer**_, and examine, how this increased ambiguity affects the quality of Vabamorf's disambiguation in EstNLTK.\n",
    "\n",
    "We use EstNLTK's version 1.6.4beta (from the commit [52c921eb3d](https://github.com/estnltk/estnltk/tree/52c921eb3d06ebc0976c0dac84bc9b9f72b0491e)), and evaluate tools on the Estonian Web Treebank (EWTB) corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Estonian Web Treebank corpus\n",
    "\n",
    "You can download the UD format EWTB corpus from here: https://github.com/UniversalDependencies/UD_Estonian-EWT/ (exact commit: [6cd4d14](https://github.com/UniversalDependencies/UD_Estonian-EWT/tree/6cd4d1480c1f3dc89bcdddab56f04dc51bfa8b48))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = 'UD_Estonian-EWT-master'\n",
    "\n",
    "import os, os.path\n",
    "from ewtb_ud_utils import load_EWTB_ud_file_with_corrections\n",
    "\n",
    "# Load corpus files with corrections\n",
    "ud_layer_name = 'ud_syntax'\n",
    "loaded_texts  = []\n",
    "for fname in os.listdir( eval_data_dir ):\n",
    "    if fname.endswith('.conllu'):\n",
    "        fpath = os.path.join( eval_data_dir, fname )\n",
    "        text = load_EWTB_ud_file_with_corrections( fpath, ud_layer_name )\n",
    "        text.meta['file'] = fname\n",
    "        loaded_texts.append( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training part of the corpus\n",
    "training_text = [text for text in loaded_texts if 'train' in text.meta['file']][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vabamorf's analysis and disambiguation (baseline: no spelling suggestions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. No spelling suggestions + Vabamorf's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_0' == VabamorfAnalyzer + PostMorphAnalysisTagger\n",
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_0')\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_0')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_0', ud_layer_name, 'morph_0_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No spelling suggestions + Vabamorf's analysis with disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_1' == VabamorfTagger\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "\n",
    "vm_tagger = VabamorfTagger(output_layer='morph_1',\n",
    "                           input_words_layer='words')\n",
    "for text in loaded_texts:\n",
    "    vm_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_1', ud_layer_name, 'morph_1_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Vabamorf's analysis and disambiguation (baseline: no spelling suggestions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Words that needed disambiguation:                6226 / 17181\n",
      "   Incorrectly disambiguated:                     541 / 6226    8.69%\n",
      "   Correctly disambiguated:                       4200 / 6226    67.46%\n",
      "   Disambiguation attempts:                       4741 / 6226    76.15%\n",
      "\n",
      "   Correct words (including undisambiguated):     5680 / 6226    91.23%\n",
      "================================================================================\n",
      " VM words alignable to UD morph words (before disamb):  16664 / 17181    96.99%\n",
      " VM words alignable to UD morph words  (after disamb):  16118 / 17181    93.81%\n"
     ]
    }
   ],
   "source": [
    "morph_0_diff = training_text.morph_0_diff_layer\n",
    "morph_1_diff = training_text.morph_1_diff_layer\n",
    "correct_analyses = 0\n",
    "words_to_disambiguate = 0\n",
    "correctly_disambiguated = 0\n",
    "correct_analyses_total_after_disamb = 0\n",
    "correct_analyses_total_before_disamb = 0\n",
    "disambiguated = 0\n",
    "for word_1, word_2 in zip(morph_0_diff, morph_1_diff):\n",
    "    if word_1.annotations[0]['full_match']:\n",
    "        # Look only words that obtained a full match:\n",
    "        # 1) with the default morphological analysis\n",
    "        correct_analyses_total_before_disamb += 1\n",
    "        if (len(word_1.annotations) > 1):\n",
    "            words_to_disambiguate += 1\n",
    "            if len(word_2.annotations) == 1:\n",
    "                disambiguated += 1\n",
    "                if word_2.annotations[0]['full_match']:\n",
    "                    correctly_disambiguated += 1\n",
    "            if word_2.annotations[0]['full_match']:\n",
    "                correct_analyses += 1\n",
    "        if word_2.annotations[0]['full_match']:\n",
    "            correct_analyses_total_after_disamb += 1\n",
    "print('='*80)\n",
    "print( ' Words that needed disambiguation:               ', words_to_disambiguate, '/', len(morph_0_diff) )\n",
    "print( '   Incorrectly disambiguated:                    ', (disambiguated-correctly_disambiguated), '/', words_to_disambiguate, '   {:.02f}%'.format(((disambiguated-correctly_disambiguated)/words_to_disambiguate)*100.0) )\n",
    "print( '   Correctly disambiguated:                      ', correctly_disambiguated, '/', words_to_disambiguate, '   {:.02f}%'.format((correctly_disambiguated/words_to_disambiguate)*100.0) )\n",
    "print( '   Disambiguation attempts:                      ', disambiguated, '/', words_to_disambiguate, '   {:.02f}%'.format((disambiguated/words_to_disambiguate)*100.0) )\n",
    "print()\n",
    "print( '   Correct words (including undisambiguated):    ', correct_analyses, '/', words_to_disambiguate, '   {:.02f}%'.format((correct_analyses/words_to_disambiguate)*100.0) )\n",
    "print('='*80)\n",
    "print( ' VM words alignable to UD morph words (before disamb): ', correct_analyses_total_before_disamb,'/', len(morph_0_diff), '   {:.02f}%'.format((correct_analyses_total_before_disamb/len(morph_0_diff))*100.0) )\n",
    "print( ' VM words alignable to UD morph words  (after disamb): ', correct_analyses_total_after_disamb,'/', len(morph_0_diff), '   {:.02f}%'.format((correct_analyses_total_after_disamb/len(morph_0_diff))*100.0) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vabamorf's analysis and disambiguation with spelling suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_data_dir = 'UD_Estonian-EWT-master'\n",
    "\n",
    "import os, os.path\n",
    "from ewtb_ud_utils import load_EWTB_ud_file_with_corrections\n",
    "\n",
    "# Load corpus files with corrections\n",
    "ud_layer_name = 'ud_syntax'\n",
    "loaded_texts  = []\n",
    "for fname in os.listdir( eval_data_dir ):\n",
    "    if fname.endswith('.conllu'):\n",
    "        fpath = os.path.join( eval_data_dir, fname )\n",
    "        text = load_EWTB_ud_file_with_corrections( fpath, ud_layer_name )\n",
    "        text.meta['file'] = fname\n",
    "        loaded_texts.append( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get training part of the corpus\n",
    "training_text = [text for text in loaded_texts if 'train' in text.meta['file']][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create VMSpellingSuggestionsTagger\n",
    "\n",
    "Make a tagger that creates a special words layer containing spelling suggestions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>normalized_words</td>\n",
       "      <td>normalized_form</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_form</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Ma</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>tahax</td>\n",
       "      <td>tahad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>tahaks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>taha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>teada</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>assju</td>\n",
       "      <td>assjõu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>asju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='normalized_words', attributes=('normalized_form',), spans=SL[Span('Ma', [{'normalized_form': None}]),\n",
       "Span('tahax', [{'normalized_form': 'tahad'}, {'normalized_form': 'tahaks'}, {'normalized_form': 'taha'}]),\n",
       "Span('teada', [{'normalized_form': None}]),\n",
       "Span('assju', [{'normalized_form': 'assjõu'}, {'normalized_form': 'asju'}]),\n",
       "Span('.', [{'normalized_form': None}])])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text, Annotation, ElementaryBaseSpan\n",
    "from estnltk.layer.layer import Layer\n",
    "from estnltk.taggers import Tagger\n",
    "from estnltk.vabamorf import morf as vm\n",
    "from estnltk.taggers.morph_analysis.morf_common import _get_word_texts\n",
    "\n",
    "class VMSpellingSuggestionsTagger(Tagger):\n",
    "    '''Creates normalized_words layer which contains spelling suggestions from Vabamorf's spellchecker.'''\n",
    "    conf_param = []\n",
    "    output_attributes = []\n",
    "    \n",
    "    def __init__(self, words_layer='words', output_layer='normalized_words'):\n",
    "        self.input_layers = [words_layer]\n",
    "        self.output_layer = output_layer\n",
    "        self.output_attributes = ('normalized_form',)\n",
    "    \n",
    "    def _make_layer(self, text, layers, status):\n",
    "        normalzed_words = Layer(name=self.output_layer,\n",
    "                                attributes=self.output_attributes,\n",
    "                                text_object=text,\n",
    "                                ambiguous=True)\n",
    "        words_layer = layers[self.input_layers[0]]\n",
    "        for word in words_layer:\n",
    "            if 'normalized_form' in words_layer.attributes:\n",
    "                word_texts = _get_word_texts(word)\n",
    "            else:\n",
    "                word_texts = [word.text]\n",
    "            suggestions = set()\n",
    "            for word_text in word_texts:\n",
    "                spell_check_result = vm.spellcheck([word_text], suggestions=True)\n",
    "                # Check if we have a misspelled word with suggestions\n",
    "                for item in spell_check_result:\n",
    "                    if not item[\"spelling\"] and len(item[\"suggestions\"]) > 0:\n",
    "                        for new_suggestion in item[\"suggestions\"]:\n",
    "                            if new_suggestion not in suggestions:\n",
    "                                suggestions.add( new_suggestion )                \n",
    "            if suggestions:\n",
    "                for suggestion in suggestions:\n",
    "                    normalzed_words.add_annotation( word.base_span, normalized_form=suggestion )\n",
    "            else:\n",
    "                normalzed_words.add_annotation( word.base_span, normalized_form=None )\n",
    "        return normalzed_words\n",
    "\n",
    "\n",
    "test_text = Text('Ma tahax teada assju.')\n",
    "test_text.tag_layer(['words'])\n",
    "VMSpellingSuggestionsTagger().tag(test_text).normalized_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply VMSpellingSuggestionsTagger on the input corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spelling_suggestor = VMSpellingSuggestionsTagger()\n",
    "for text in loaded_texts:\n",
    "    spelling_suggestor.tag( text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. No spelling suggestions + Vabamorf's analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_0')\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_0')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_0', ud_layer_name, 'morph_0_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Spelling suggestions + Vabamorf's analysis only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_1' == VabamorfAnalyzer + PostMorphAnalysisTagger\n",
    "from estnltk.taggers import VabamorfAnalyzer, PostMorphAnalysisTagger\n",
    "\n",
    "vm_analyser = VabamorfAnalyzer(output_layer='morph_1',\n",
    "                               input_words_layer=spelling_suggestor.output_layer)\n",
    "post_corrector = PostMorphAnalysisTagger(output_layer='morph_1')\n",
    "for text in loaded_texts:\n",
    "    vm_analyser.tag( text )\n",
    "    post_corrector.retag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_1', ud_layer_name, 'morph_1_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Spelling suggestions + Vabamorf's analysis with disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'morph_2' == VabamorfTagger\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "\n",
    "vm_tagger = VabamorfTagger(output_layer='morph_2',\n",
    "                           input_words_layer=spelling_suggestor.output_layer)\n",
    "for text in loaded_texts:\n",
    "    vm_tagger.tag( text )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ewtb_ud_utils import VM2UDMorphFullDiffTagger\n",
    "vm2ud_diff_tagger = VM2UDMorphFullDiffTagger('morph_2', ud_layer_name, 'morph_2_diff_layer')\n",
    "# Find differences\n",
    "for text in loaded_texts:\n",
    "    vm2ud_diff_tagger.tag(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results: Vabamorf's analysis and disambiguation after spelling suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(training_text.morph_0_diff_layer) == len(training_text.morph_1_diff_layer)\n",
    "assert len(training_text.morph_1_diff_layer) == len(training_text.morph_2_diff_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Words that needed disambiguation:                6370 / 17181\n",
      "   Incorrectly disambiguated:                     658 / 6370    10.33%\n",
      "   Correctly disambiguated:                       4199 / 6370    65.92%\n",
      "   Disambiguation attempts:                       4857 / 6370    76.25%\n",
      "\n",
      "   Correct words (including undisambiguated):     5701 / 6370    89.50%\n",
      "================================================================================\n",
      " VM words alignable to UD morph words (before disamb):  16820 / 17181    97.90%\n",
      " VM words alignable to UD morph words  (after disamb):  16111 / 17181    93.77%\n"
     ]
    }
   ],
   "source": [
    "morph_0_diff = training_text.morph_0_diff_layer\n",
    "morph_1_diff = training_text.morph_1_diff_layer\n",
    "morph_2_diff = training_text.morph_2_diff_layer\n",
    "correct_analyses = 0\n",
    "words_to_disambiguate = 0\n",
    "correctly_disambiguated = 0\n",
    "correct_analyses_total_after_disamb = 0\n",
    "correct_analyses_total_before_disamb = 0\n",
    "disambiguated = 0\n",
    "for word_1, word_2, word_3 in zip(morph_0_diff, morph_1_diff, morph_2_diff):\n",
    "    if word_1.annotations[0]['full_match'] or word_2.annotations[0]['full_match']:\n",
    "        # Look only words that obtained a full match:\n",
    "        # 1) with the default morphological analysis, or\n",
    "        # 2) with the extended morphological analysis based on normalized word forms\n",
    "        correct_analyses_total_before_disamb += 1\n",
    "        if (len(word_1.annotations) > 1 or len(word_2.annotations) > 1):\n",
    "            words_to_disambiguate += 1\n",
    "            if len(word_3.annotations) == 1:\n",
    "                disambiguated += 1\n",
    "                if word_3.annotations[0]['full_match']:\n",
    "                    correctly_disambiguated += 1\n",
    "            if word_3.annotations[0]['full_match']:\n",
    "                correct_analyses += 1\n",
    "        if word_3.annotations[0]['full_match']:\n",
    "            correct_analyses_total_after_disamb += 1\n",
    "print('='*80)\n",
    "print( ' Words that needed disambiguation:               ', words_to_disambiguate, '/', len(morph_0_diff) )\n",
    "print( '   Incorrectly disambiguated:                    ', (disambiguated-correctly_disambiguated), '/', words_to_disambiguate, '   {:.02f}%'.format(((disambiguated-correctly_disambiguated)/words_to_disambiguate)*100.0) )\n",
    "print( '   Correctly disambiguated:                      ', correctly_disambiguated, '/', words_to_disambiguate, '   {:.02f}%'.format((correctly_disambiguated/words_to_disambiguate)*100.0) )\n",
    "print( '   Disambiguation attempts:                      ', disambiguated, '/', words_to_disambiguate, '   {:.02f}%'.format((disambiguated/words_to_disambiguate)*100.0) )\n",
    "print()\n",
    "print( '   Correct words (including undisambiguated):    ', correct_analyses, '/', words_to_disambiguate, '   {:.02f}%'.format((correct_analyses/words_to_disambiguate)*100.0) )\n",
    "print('='*80)\n",
    "print( ' VM words alignable to UD morph words (before disamb): ', correct_analyses_total_before_disamb,'/', len(morph_0_diff), '   {:.02f}%'.format((correct_analyses_total_before_disamb/len(morph_0_diff))*100.0) )\n",
    "print( ' VM words alignable to UD morph words  (after disamb): ', correct_analyses_total_after_disamb,'/', len(morph_0_diff), '   {:.02f}%'.format((correct_analyses_total_after_disamb/len(morph_0_diff))*100.0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      " Only words with normalizations (spelling suggestions):  409 / 17181\n",
      "   Correctly analysed (without disambiguation):          162 / 409    39.61%\n",
      "       - Correctly disambiguated:                        131 / 409    32.03%\n",
      "       - Incorrectly disambiguated:                      31 / 409    7.58%\n",
      "   Word's analyses cannot be matched to UD word's:       247 / 409    60.39%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine-grained analysis: how much of the normalized words were actually correctly disambiguated?\n",
    "from estnltk.taggers.morph_analysis.morf_common import _get_word_texts\n",
    "norm_words   = training_text[spelling_suggestor.output_layer]\n",
    "morph_1_diff = training_text.morph_1_diff_layer\n",
    "morph_2_diff = training_text.morph_2_diff_layer\n",
    "words_with_normalization = 0\n",
    "words_with_normalization_aligned_before_disamb = 0\n",
    "words_with_normalization_aligned_after_disamb  = 0\n",
    "for norm_word, word_2, word_3 in zip(norm_words, morph_1_diff, morph_2_diff):\n",
    "    w_texts = _get_word_texts(norm_word)\n",
    "    if len(w_texts) > 1 or (len(w_texts) == 1 and w_texts[0] != norm_word.text):\n",
    "        words_with_normalization += 1\n",
    "        if word_2.annotations[0]['full_match']:\n",
    "            words_with_normalization_aligned_before_disamb += 1\n",
    "        if word_3.annotations[0]['full_match']:\n",
    "            words_with_normalization_aligned_after_disamb += 1\n",
    "print('='*80)\n",
    "print( ' Only words with normalizations (spelling suggestions): ', words_with_normalization, '/', len(morph_1_diff) )\n",
    "print( '   Correctly analysed (without disambiguation):         ', words_with_normalization_aligned_before_disamb, '/', words_with_normalization, '   {:.02f}%'.format((words_with_normalization_aligned_before_disamb/words_with_normalization)*100.0) )\n",
    "print( '       - Correctly disambiguated:                       ', words_with_normalization_aligned_after_disamb, '/', words_with_normalization, '   {:.02f}%'.format((words_with_normalization_aligned_after_disamb/words_with_normalization)*100.0) )\n",
    "incorrect = words_with_normalization_aligned_before_disamb - words_with_normalization_aligned_after_disamb\n",
    "print( '       - Incorrectly disambiguated:                     ', incorrect, '/', words_with_normalization, '   {:.02f}%'.format((incorrect/words_with_normalization)*100.0) )\n",
    "norm_words_no_ud_match = words_with_normalization - words_with_normalization_aligned_before_disamb\n",
    "print( '   Word\\'s analyses cannot be matched to UD word\\'s:      ', norm_words_no_ud_match, '/', words_with_normalization, '   {:.02f}%'.format((norm_words_no_ud_match/words_with_normalization)*100.0) )\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    All measurements made on the training part of the EWTB corpus\n",
    "    \n",
    "    A) Vabamorf's analysis & disambiguation (baseline: no spelling corrections)\n",
    "    ================================================================================\n",
    "     Words that needed disambiguation:                6226 / 17181\n",
    "       Incorrectly disambiguated:                     541 / 6226      8.69%\n",
    "       Correctly disambiguated:                       4200 / 6226    67.46%\n",
    "       Disambiguation attempts:                       4741 / 6226    76.15%\n",
    "\n",
    "       Correct words (including undisambiguated):     5680 / 6226    91.23%\n",
    "    ================================================================================\n",
    "     VM words alignable to UD morph words (before disamb):  16664 / 17181    96.99%\n",
    "     VM words alignable to UD morph words  (after disamb):  16118 / 17181    93.81%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    B) Vabamorf's analysis & disambiguation on words with spelling suggestions\n",
    "    ================================================================================\n",
    "     Words that needed disambiguation:                6372 / 17181\n",
    "       Incorrectly disambiguated:                     660 / 6372     10.36%\n",
    "       Correctly disambiguated:                       4199 / 6372    65.90%\n",
    "       Disambiguation attempts:                       4859 / 6372    76.26%\n",
    "\n",
    "       Correct words (including undisambiguated):     5701 / 6372    89.47%\n",
    "    ================================================================================\n",
    "     VM words alignable to UD morph words (before disamb):  16820 / 17181    97.90%\n",
    "     VM words alignable to UD morph words  (after disamb):  16103 / 17181    93.73%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     ================================================================================\n",
    "     Only words with normalizations (spelling suggestions):  409 / 17181\n",
    "       Correctly analysed (without disambiguation):          162 / 409    39.61%\n",
    "           - Correctly disambiguated:                        131 / 409    32.03%\n",
    "           - Incorrectly disambiguated:                      31 / 409      7.58%\n",
    "       Word's analyses cannot be matched to UD word's:       247 / 409    60.39%\n",
    "     ================================================================================\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
